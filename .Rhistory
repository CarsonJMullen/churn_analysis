}
columns_to_convert <- c("Partner", "Dependents", "PhoneService", "OnlineSecurity",
"OnlineBackup", "DeviceProtection", "TechSupport",
"StreamingTV", "StreamingMovies", "PaperlessBilling",
"MultipleLines", "Churn")
# Use lapply to apply the convert_to_binary function to each column in the list
df[columns_to_convert] <- lapply(df[columns_to_convert], convert_to_binary)
df$gender = ifelse(df$gender == "Female", 1, 0)
df$Churn <- factor(df$Churn)
##### Split into Test/Train Split
set.seed(123)
trainIndex <- createDataPartition(df$Churn, p = 0.7, list = FALSE)
train_df <- df[trainIndex, ]
test_df <- df[-trainIndex, ]
##### Building Models
#Creates a model with all variables
full_model <- glm(Churn ~ . - customerID - TotalCharges+ tenure*StreamingMovies, data = train_df, family = binomial)
#Creates a model with all variables & interactions b/t all variables
full_interaction_model <- glm(Churn ~ (. - customerID)^2, data = train_df, family = binomial)
#Summaries
summary(full_model)
summary(full_interaction_model)
#Backward Selection
backward_model <- step(full_model, direction = "backward")
#Forward Selection
null_model <- glm(Churn ~ 1, data = df, family = binomial)
forward_model <- stepAIC(null_model, direction = "forward", scope = formula(full_model), trace = FALSE)
#Stepwise Selection
stepwise_model <- step(forward_model, scope=formula(full_model), direction="both")
summary(backward_model)
summary(forward_model)
summary(stepwise_model)
backward_predictions <- predict(backward_model,newdata=test_df,type='response')
sum(backward_predictions %>% round == test_df$Churn)/length(test_df$Churn)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.5, 1, 0)
xtabs(~predicted.model + test_df$Churn)
####################
# Assuming 'predictions' is the vector of predicted probabilities or scores
# and 'labels' is the vector of true binary labels (0 or 1)
roc_curve <- roc(test_df$Churn, predicted.model)
auc(roc_curve)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
FNR
TPR
xtabs(~predicted.model + test_df$Churn)
TPR <- TP/(TP + FN)
TPR
library(tidyverse)
library(dplyr)
library(caret)
library(MASS)
library(pROC)
# Read data, make sure you set your directory
df <- read.csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')
df <- na.omit(df)
# Create a function to convert "Yes" to 1 and "No" to 0
convert_to_binary <- function(column){
ifelse(column == "Yes", as.factor(1), as.factor(0))
}
columns_to_convert <- c("Partner", "Dependents", "PhoneService", "OnlineSecurity",
"OnlineBackup", "DeviceProtection", "TechSupport",
"StreamingTV", "StreamingMovies", "PaperlessBilling",
"MultipleLines", "Churn")
# Use lapply to apply the convert_to_binary function to each column in the list
df[columns_to_convert] <- lapply(df[columns_to_convert], convert_to_binary)
df$gender = ifelse(df$gender == "Female", 1, 0)
df$Churn <- factor(df$Churn)
##### Split into Test/Train Split
set.seed(123)
trainIndex <- createDataPartition(df$Churn, p = 0.7, list = FALSE)
train_df <- df[trainIndex, ]
test_df <- df[-trainIndex, ]
##### Building Models
#Creates a model with all variables
full_model <- glm(Churn ~ . - customerID - TotalCharges+ tenure*StreamingMovies, data = train_df, family = binomial)
#Creates a model with all variables & interactions b/t all variables
full_interaction_model <- glm(Churn ~ (. - customerID)^2, data = train_df, family = binomial)
#Summaries
summary(full_model)
summary(full_interaction_model)
#Backward Selection
backward_model <- step(full_model, direction = "backward")
#Forward Selection
null_model <- glm(Churn ~ 1, data = df, family = binomial)
forward_model <- stepAIC(null_model, direction = "forward", scope = formula(full_model), trace = FALSE)
#Stepwise Selection
stepwise_model <- step(forward_model, scope=formula(full_model), direction="both")
summary(backward_model)
summary(forward_model)
summary(stepwise_model)
backward_predictions <- predict(backward_model,newdata=test_df,type='response')
sum(backward_predictions %>% round == test_df$Churn)/length(test_df$Churn)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.5, 1, 0)
xtabs(~predicted.model + test_df$Churn)
####################
# Assuming 'predictions' is the vector of predicted probabilities or scores
# and 'labels' is the vector of true binary labels (0 or 1)
roc_curve <- roc(test_df$Churn, predicted.model)
library(tidyverse)
library(dplyr)
library(caret)
library(MASS)
library(pROC)
# Read data, make sure you set your directory
df <- read.csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')
df <- na.omit(df)
# Create a function to convert "Yes" to 1 and "No" to 0
convert_to_binary <- function(column){
ifelse(column == "Yes", as.numeric(1), as.numeric(0))
}
columns_to_convert <- c("Partner", "Dependents", "PhoneService", "OnlineSecurity",
"OnlineBackup", "DeviceProtection", "TechSupport",
"StreamingTV", "StreamingMovies", "PaperlessBilling",
"MultipleLines", "Churn")
# Use lapply to apply the convert_to_binary function to each column in the list
df[columns_to_convert] <- lapply(df[columns_to_convert], convert_to_binary)
df$gender = ifelse(df$gender == "Female", 1, 0)
df$Churn <- factor(df$Churn)
##### Split into Test/Train Split
set.seed(123)
trainIndex <- createDataPartition(df$Churn, p = 0.7, list = FALSE)
train_df <- df[trainIndex, ]
test_df <- df[-trainIndex, ]
##### Building Models
#Creates a model with all variables
full_model <- glm(Churn ~ . - customerID - TotalCharges+ tenure*StreamingMovies, data = train_df, family = binomial)
#Creates a model with all variables & interactions b/t all variables
full_interaction_model <- glm(Churn ~ (. - customerID)^2, data = train_df, family = binomial)
#Summaries
summary(full_model)
summary(full_interaction_model)
#Backward Selection
backward_model <- step(full_model, direction = "backward")
#Forward Selection
null_model <- glm(Churn ~ 1, data = df, family = binomial)
forward_model <- stepAIC(null_model, direction = "forward", scope = formula(full_model), trace = FALSE)
#Stepwise Selection
stepwise_model <- step(forward_model, scope=formula(full_model), direction="both")
summary(backward_model)
summary(forward_model)
summary(stepwise_model)
backward_predictions <- predict(backward_model,newdata=test_df,type='response')
sum(backward_predictions %>% round == test_df$Churn)/length(test_df$Churn)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.5, 1, 0)
xtabs(~predicted.model + test_df$Churn)
####################
# Assuming 'predictions' is the vector of predicted probabilities or scores
# and 'labels' is the vector of true binary labels (0 or 1)
roc_curve <- roc(test_df$Churn, predicted.model)
auc(roc_curve)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
TPR
auc(roc_curve)
library(tidyverse)
library(dplyr)
library(caret)
library(MASS)
library(pROC)
# Read data, make sure you set your directory
df <- read.csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')
df <- na.omit(df)
# Create a function to convert "Yes" to 1 and "No" to 0
convert_to_binary <- function(column){
ifelse(column == "Yes", as.numeric(1), as.numeric(0))
}
columns_to_convert <- c("Partner", "Dependents", "PhoneService", "OnlineSecurity",
"OnlineBackup", "DeviceProtection", "TechSupport",
"StreamingTV", "StreamingMovies", "PaperlessBilling",
"MultipleLines", "Churn")
# Use lapply to apply the convert_to_binary function to each column in the list
df[columns_to_convert] <- lapply(df[columns_to_convert], convert_to_binary)
#df$gender = ifelse(df$gender == "Female", 1, 0)
df$Churn <- factor(df$Churn)
##### Split into Test/Train Split
set.seed(123)
trainIndex <- createDataPartition(df$Churn, p = 0.7, list = FALSE)
train_df <- df[trainIndex, ]
test_df <- df[-trainIndex, ]
##### Building Models
#Creates a model with all variables
full_model <- glm(Churn ~ . - customerID - TotalCharges+ tenure*StreamingMovies, data = train_df, family = binomial)
#Creates a model with all variables & interactions b/t all variables
full_interaction_model <- glm(Churn ~ (. - customerID)^2, data = train_df, family = binomial)
#Summaries
summary(full_model)
summary(full_interaction_model)
#Backward Selection
backward_model <- step(full_model, direction = "backward")
#Forward Selection
null_model <- glm(Churn ~ 1, data = df, family = binomial)
forward_model <- stepAIC(null_model, direction = "forward", scope = formula(full_model), trace = FALSE)
#Stepwise Selection
stepwise_model <- step(forward_model, scope=formula(full_model), direction="both")
summary(backward_model)
summary(forward_model)
summary(stepwise_model)
backward_predictions <- predict(backward_model,newdata=test_df,type='response')
sum(backward_predictions %>% round == test_df$Churn)/length(test_df$Churn)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.5, 1, 0)
xtabs(~predicted.model + test_df$Churn)
####################
# Assuming 'predictions' is the vector of predicted probabilities or scores
# and 'labels' is the vector of true binary labels (0 or 1)
roc_curve <- roc(test_df$Churn, predicted.model)
auc(roc_curve)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
summary(backward_model)
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
TPR
library(tidyverse)
library(dplyr)
library(caret)
library(MASS)
library(pROC)
# Read data, make sure you set your directory
df <- read.csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')
df <- na.omit(df)
# Create a function to convert "Yes" to 1 and "No" to 0
convert_to_binary <- function(column){
ifelse(column == "Yes", as.numeric(1), as.numeric(0))
}
columns_to_convert <- c("Partner", "Dependents", "PhoneService", "OnlineSecurity",
"OnlineBackup", "DeviceProtection", "TechSupport",
"StreamingTV", "StreamingMovies", "PaperlessBilling",
"MultipleLines", "Churn")
# Use lapply to apply the convert_to_binary function to each column in the list
df[columns_to_convert] <- lapply(df[columns_to_convert], convert_to_binary)
df$gender = ifelse(df$gender == "Female", 1, 0)
df$Churn <- factor(df$Churn)
##### Split into Test/Train Split
set.seed(123)
trainIndex <- createDataPartition(df$Churn, p = 0.7, list = FALSE)
train_df <- df[trainIndex, ]
test_df <- df[-trainIndex, ]
##### Building Models
#Creates a model with all variables
full_model <- glm(Churn ~ . - customerID - TotalCharges+ tenure*StreamingMovies, data = train_df, family = binomial)
#Creates a model with all variables & interactions b/t all variables
full_interaction_model <- glm(Churn ~ (. - customerID)^2, data = train_df, family = binomial)
#Summaries
summary(full_model)
summary(full_interaction_model)
#Backward Selection
backward_model <- step(full_model, direction = "backward")
#Forward Selection
null_model <- glm(Churn ~ 1, data = df, family = binomial)
forward_model <- stepAIC(null_model, direction = "forward", scope = formula(full_model), trace = FALSE)
#Stepwise Selection
stepwise_model <- step(forward_model, scope=formula(full_model), direction="both")
summary(backward_model)
summary(forward_model)
summary(stepwise_model)
backward_predictions <- predict(backward_model,newdata=test_df,type='response')
sum(backward_predictions %>% round == test_df$Churn)/length(test_df$Churn)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.4, 1, 0)
xtabs(~predicted.model + test_df$Churn)
####################
# Assuming 'predictions' is the vector of predicted probabilities or scores
# and 'labels' is the vector of true binary labels (0 or 1)
roc_curve <- roc(test_df$Churn, predicted.model)
auc(roc_curve)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
roc_curve <- roc(test_df$Churn, predict(backward_model,newdata=test_df,type='response'))
auc(roc_curve)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
TPR
TNR
FPR
FNR
FN
FN
xtabs(~predicted.model + test_df$Churn)
176/(176+384)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.2, 1, 0)
xtabs(~predicted.model + test_df$Churn)
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
TPR
TNR
FNR
auc(roc_curve)
cf <- confusionMatrix(data=predicted.model,
reference=df$Churn)
print(cf)
cf <- caret::confusionMatrix(data=predicted.model,
reference=df$Churn)
f$Churn
df$Churn
cf <- caret::confusionMatrix(data=predicted.model, reference=as.numeric(df$Churn))
cf <- caret::confusionMatrix(data=as.numeric(predicted.model), reference=as.numeric(df$Churn))
levels(predicted.model)
levels(df$Churn)
factor(predicted.mode, levels = c("0", "1"))
factor(predicted.model, levels = c("0", "1"))
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TP
xtabs(~predicted.model + test_df$Churn)
TPR <- TP/(TP + FN)
TPR
levels(df$Churn)
levels(predicted.model)
cf <- caret::confusionMatrix(data=predicted.model, reference=df$Churn)
length(predicted.model)
length(df$Churn)
length(test_df$Churn)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.5, 1, 0)
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.4, 1, 0)
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.45, 1, 0)
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.55, 1, 0)
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
#Set the threshold
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.8, 1, 0)
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.62, 1, 0)
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.6, 1, 0)
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
predicted.model <- ifelse(predict(backward_model,newdata=test_df,type='response') >= 0.55, 1, 0)
predicted.model <- factor(predicted.model, levels = c("0", "1"))
#Calculate values of
TP <- sum(test_df$Churn == predicted.model & test_df$Churn == 1)
TN <- sum(test_df$Churn == predicted.model & test_df$Churn == 0)
FN <- sum(test_df$Churn != predicted.model & test_df$Churn == 1)
FP <- sum(test_df$Churn != predicted.model & test_df$Churn == 0)
TPR <- TP/(TP + FN)
TNR <- TN/(TN + FP)
FPR <- FP/(FP + TN)
FNR <- FN/(FN + TP)
cf <- caret::confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
xtabs(~predicted.model + test_df$Churn)
# Confusion Matrix
cf <- confusionMatrix(data=predicted.model, reference=test_df$Churn)
print(cf)
# Calculate the lift values
lift_data <- lift(test_df$Churn, predict(backward_model,newdata=test_df,type='response'))
# Calculate the lift values
lift_data <- lift(test_df$Churn, predict(backward_model,newdata=test_df,type='response'))
library(pROC)
# Calculate the lift values
lift_data <- lift(test_df$Churn, predict(backward_model,newdata=test_df,type='response'))
# Calculate the lift values
lift_data <- lift_curve(test_df$Churn, predict(backward_model,newdata=test_df,type='response'))
library(ggplot2)
# Calculate the lift values
lift_data <- Lift(test_df$Churn, predict(backward_model,newdata=test_df,type='response'))
# Calculate the lift values
lift_data <- lift(test_df$Churn, predict(backward_model,newdata=test_df,type='response'))
?pROC
ci.auc(roc_curve)
# Area under the curve for ROC
auc(roc_curve)
#backward_predictions <- predict(backward_model,newdata=test_df,type='response')
backward_predictions <- predict(forward_model,newdata=test_df,type='response')
# Plot values of ROC curve
roc_curve <- roc(test_df$Churn, predict(forward_model,newdata=test_df,type='response'))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
# Area under the curve for ROC
auc(roc_curve)
summary(forward_model)
forward_model <- stepAIC(null_model, direction = "forward", scope = formula(full_model), trace = FALSE)
#Stepwise Selection
stepwise_model <- step(forward_model, scope=formula(full_model), direction="both")
summary(stepwise_model)
exp
exp(1)
exp(-1.417277)
0.2423731 - 1
exp(-0.043255)
-1
0.9576672-1
exp(-0.043255)
exp(-0.043255*2)
1-0.9171264
-0.0423328*2
backward_model$coefficients
exp(-0.02389558)
1-0.9763877
0.9763877-1
varImp(backward_model)
